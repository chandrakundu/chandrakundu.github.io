<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>How to Create a Chatbot Like ChatGPT by Running LLM Locally in Windows via Ollama and Open WebUI - Chandra Kundu | PhD Candidate at UCF</title><meta name="author" content="Chandra Kundu">
<meta name="description" content="In this post we will see that how to create a chatbot like ChatGPT by running Large Language Model (LLM) locally in Windows via Ollama and Open WebUI
Creating a chatbot that runs a large language model (LLM) on your local machine can be done in several ways. Here are some methods you might consider:
Using API and Programming: This approach is often difficult and time-consuming. Chatbot UI: This method requires API access from OpenAI. It&rsquo;s very good if you want to use it remotely, but as of my knowledge, it may not support local model access. Ollama and Open WebUI: These can be used with APIs from OpenAI and locally stored, trained LLM models. In this post, I will discuss how we can use Ollama and Open WebUI.
"><meta name="keywords" content='Chatbot, LLM, Ollama, Open WebUI'>
  <meta itemprop="name" content="How to create a chatbot like ChatGPT by running LLM locally in Windows via Ollama and Open WebUI">
  <meta itemprop="description" content="In this post we will see that how to create a chatbot like ChatGPT by running Large Language Model (LLM) locally in Windows via Ollama and Open WebUI
Creating a chatbot that runs a large language model (LLM) on your local machine can be done in several ways. Here are some methods you might consider:
Using API and Programming: This approach is often difficult and time-consuming. Chatbot UI: This method requires API access from OpenAI. It’s very good if you want to use it remotely, but as of my knowledge, it may not support local model access. Ollama and Open WebUI: These can be used with APIs from OpenAI and locally stored, trained LLM models. In this post, I will discuss how we can use Ollama and Open WebUI.">
  <meta itemprop="datePublished" content="2024-06-12T00:37:12-04:00">
  <meta itemprop="dateModified" content="2024-06-17T00:29:37-04:00">
  <meta itemprop="wordCount" content="596">
  <meta itemprop="image" content="https://chandrakundu.github.io/chandra-kundu.png">
  <meta itemprop="keywords" content="Chatbot,LLM,Ollama,Open WebUI"><meta property="og:url" content="https://chandrakundu.github.io/posts/how-to-create-ai-chatbot/">
  <meta property="og:site_name" content="Chandra Kundu | PhD Candidate at UCF">
  <meta property="og:title" content="How to create a chatbot like ChatGPT by running LLM locally in Windows via Ollama and Open WebUI">
  <meta property="og:description" content="In this post we will see that how to create a chatbot like ChatGPT by running Large Language Model (LLM) locally in Windows via Ollama and Open WebUI
Creating a chatbot that runs a large language model (LLM) on your local machine can be done in several ways. Here are some methods you might consider:
Using API and Programming: This approach is often difficult and time-consuming. Chatbot UI: This method requires API access from OpenAI. It’s very good if you want to use it remotely, but as of my knowledge, it may not support local model access. Ollama and Open WebUI: These can be used with APIs from OpenAI and locally stored, trained LLM models. In this post, I will discuss how we can use Ollama and Open WebUI.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-12T00:37:12-04:00">
    <meta property="article:modified_time" content="2024-06-17T00:29:37-04:00">
    <meta property="og:image" content="https://chandrakundu.github.io/chandra-kundu.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://chandrakundu.github.io/chandra-kundu.png">
  <meta name="twitter:title" content="How to create a chatbot like ChatGPT by running LLM locally in Windows via Ollama and Open WebUI">
  <meta name="twitter:description" content="In this post we will see that how to create a chatbot like ChatGPT by running Large Language Model (LLM) locally in Windows via Ollama and Open WebUI
Creating a chatbot that runs a large language model (LLM) on your local machine can be done in several ways. Here are some methods you might consider:
Using API and Programming: This approach is often difficult and time-consuming. Chatbot UI: This method requires API access from OpenAI. It’s very good if you want to use it remotely, but as of my knowledge, it may not support local model access. Ollama and Open WebUI: These can be used with APIs from OpenAI and locally stored, trained LLM models. In this post, I will discuss how we can use Ollama and Open WebUI.">
<meta name="application-name" content="Chandra Kundu | PhD Candidate at UCF">
<meta name="apple-mobile-web-app-title" content="Chandra Kundu | PhD Candidate at UCF"><meta name="theme-color" data-light="#ffffff" data-dark="#ffffff" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" type="text/html" href="https://chandrakundu.github.io/posts/how-to-create-ai-chatbot/" title="How to create a chatbot like ChatGPT by running LLM locally in Windows via Ollama and Open WebUI - Chandra Kundu | PhD Candidate at UCF" /><link rel="prev" type="text/html" href="https://chandrakundu.github.io/posts/latex-tips-for-effective-typesetting/" title="LaTeX Tips for Effective Typesetting" /><link rel="next" type="text/html" href="https://chandrakundu.github.io/posts/how-to-generate-images-locally-using-open-source-ai-models/" title="How to Generate Images Locally Using Open Source AI Models" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><meta name="google-site-verification" content="0jwgmOu3-q1Tr-PJlcVJTwxYw-d9yLM7nyySKD9W85Y" /><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "How to create a chatbot like ChatGPT by running LLM locally in Windows via Ollama and Open WebUI",
    "inLanguage": "en",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/chandrakundu.github.io\/posts\/how-to-create-ai-chatbot\/"
    },"image": ["https:\/\/chandrakundu.github.io\/chandra-kundu.jpg"],"genre": "posts","wordcount":  596 ,
    "url": "https:\/\/chandrakundu.github.io\/posts\/how-to-create-ai-chatbot\/","datePublished": "2024-06-12T00:37:12-04:00","dateModified": "2024-06-17T00:29:37-04:00","publisher": {
      "@type": "Organization",
      "name": "Chandra Kundu","logo": "https:\/\/chandrakundu.github.io\/chandra-kundu.jpg"},"author": {
        "@type": "Person",
        "name": "Chandra Kundu"
      },"description": ""
  }
  </script><script src="/js/head/color-scheme.min.js"></script></head>
  <body data-header-desktop="fixed" data-header-mobile="auto"><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/" title="Chandra Kundu | PhD Candidate at UCF"><span class="header-title-text">Chandra Kundu</span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a class="menu-link" href="/">Home</a></li><li class="menu-item">
              <a class="menu-link" href="/research/">Research</a></li><li class="menu-item">
              <a class="menu-link" href="/teaching/">Teaching</a></li><li class="menu-item">
              <a class="menu-link" href="/cv/">CV</a></li><li class="menu-item">
              <a class="menu-link" href="/posts/">Posts</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="Search titles or contents ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="Chandra Kundu | PhD Candidate at UCF"><span class="header-title-text">Chandra Kundu</span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="Search titles or contents ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              Cancel
            </a>
          </li><li class="menu-item"><a class="menu-link" href="/">Home</a></li><li class="menu-item"><a class="menu-link" href="/research/">Research</a></li><li class="menu-item"><a class="menu-link" href="/teaching/">Teaching</a></li><li class="menu-item"><a class="menu-link" href="/cv/">CV</a></li><li class="menu-item"><a class="menu-link" href="/posts/">Posts</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container container-reverse"><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label="Collections"></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>How to Create a Chatbot Like ChatGPT by Running LLM Locally in Windows via Ollama and Open WebUI</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      Chandra Kundu</span></span><span class="post-included-in">&nbsp;included in <a href="/categories/ai/" class="post-category" title="Category - AI"><i class="fa-regular fa-folder fa-fw" aria-hidden="true"></i> AI</a></span></div><div class="post-meta-line"><span title="published on 2024-06-12 00:37:12"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden="true"></i><time datetime="2024-06-12">2024-06-12</time></span>&nbsp;<span title="Updated on 2024-06-17 00:29:37"><i class="fa-regular fa-calendar-check fa-fw me-1" aria-hidden="true"></i><time datetime="2024-06-17">2024-06-17</time></span>&nbsp;<span title="596 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 600 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>3 minutes</span>&nbsp;</div>
    </div><div class="featured-image"><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fot7Pg4wbBALlLQzQBzumQ.png" alt="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fot7Pg4wbBALlLQzQBzumQ.png" data-title="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fot7Pg4wbBALlLQzQBzumQ.png" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></div><div class="details toc" id="toc-static" data-kept="true">
        <div class="details-summary toc-title">
          <span>Contents</span>
          <span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#install-ollama">Install Ollama</a></li>
    <li><a href="#install-open-webui">Install Open WebUI</a></li>
    <li><a href="#installing-new-models">Installing New Models</a></li>
    <li><a href="#how-to-start-using-open-webui-later-on">How to start using Open WebUI later on</a>
      <ul>
        <li><a href="#troubleshooting">Troubleshooting</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div class="content" id="content"><p>In this post we will see that how to create a chatbot like ChatGPT by running Large Language Model (LLM) locally in Windows via Ollama and Open WebUI</p>
<p>Creating a chatbot that runs a large language model (LLM) on your local machine can be done in several ways. Here are some methods you might consider:</p>
<ul>
<li><strong>Using API and Programming:</strong> This approach is often difficult and time-consuming.</li>
<li><strong>Chatbot UI:</strong> This method requires API access from OpenAI. It&rsquo;s very good if you want to use it remotely, but as of my knowledge, it may not support local model access.</li>
<li><strong>Ollama and Open WebUI:</strong> These can be used with APIs from OpenAI and locally stored, trained LLM models.</li>
</ul>
<p>In this post, I will discuss how we can use <strong>Ollama</strong> and <strong>Open WebUI</strong>.</p>
<h2 id="install-ollama" class="heading-element"><span>Install Ollama</span>
  <a href="#install-ollama" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>Ollama is a framework for building and running language models on a local machine. It can be used for not only chatbots but also AI assistants inside your editor like VSCode. For more information, you can explore <a href="https://ollama.com/blog"target="_blank" rel="external nofollow noopener noreferrer">Ollama&rsquo;s blog</a> and <a href="https://ollama.com/blog/continue-code-assistant"target="_blank" rel="external nofollow noopener noreferrer">Continue Code Assistant</a>.</p>
<p>Ollama supports Nvidia and Apple&rsquo;s M-series GPUs. Nvidia GPUs with at least 4 GB of memory will work, and for M-series Macs, at least 16 GB of memory is recommended. I suggests using at least a GeForce RTX 3060 Ti GPU with 8 GB GDDR6 memory. While Ollama can run in CPU-only mode, the responses may be slow or poor quality. For instance, one user reported that a smaller model, <code>tinyllama</code>, was able to stream responses at a normal rate but the quality was poor.</p>
<ol>
<li>Download Ollama from <a href="https://ollama.com/download/windows"target="_blank" rel="external nofollow noopener noreferrer">here</a> and install it.</li>
<li>Available Ollama models can be found <a href="https://ollama.com/library"target="_blank" rel="external nofollow noopener noreferrer">here</a>.</li>
<li>To run a particular model, open the terminal and run the Ollama command. For example, to run <code>llama3:8B</code>, use:
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">ollama run llama3:8B</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>Once running, you can visit <a href="http://localhost:11434/"target="_blank" rel="external nofollow noopener noreferrer">http://localhost:11434/</a> to confirm if Ollama is running.</li>
</ol>
<p>For additional documentation, refer to their <a href="https://github.com/ollama/ollama"target="_blank" rel="external nofollow noopener noreferrer">documentation</a>.</p>
<h2 id="install-open-webui" class="heading-element"><span>Install Open WebUI</span>
  <a href="#install-open-webui" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>We will be using Docker Desktop.</p>
<ol>
<li>Download and install Docker Desktop from <a href="https://www.docker.com/products/docker-desktop"target="_blank" rel="external nofollow noopener noreferrer">here</a>.</li>
<li>To confirm the Docker installation, run the following command in the terminal: <code>docker --version</code> and it should display the Docker version.</li>
<li>If you have an Nvidia GPU and want GPU support with the OpenAI API, use the following command:
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker run -d -p 3000:8080 --gpus all --add-host<span class="o">=</span>host.docker.internal:host-gateway -e <span class="nv">OPENAI_API_KEY</span><span class="o">=</span>openai_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<p>Remember to replace openai_secret_key with your secret key, which can be found <a href="https://platform.openai.com/api-keys"target="_blank" rel="external nofollow noopener noreferrer">here</a>.</p>
<p>If you want to install without GPU or without OpenAI API, follow the instructions provided <a href="https://github.com/open-webui/open-webui"target="_blank" rel="external nofollow noopener noreferrer">here</a>.</p>
<p>Once installed, you can visit <a href="http://localhost:3000/"target="_blank" rel="external nofollow noopener noreferrer">http://localhost:3000/</a>, sign up, and start using it.</p>
<h2 id="installing-new-models" class="heading-element"><span>Installing New Models</span>
  <a href="#installing-new-models" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>To install a new model, you can use <code>ollama run &lt;model name&gt;</code> in the terminal. To find new models visit <a href="https://ollama.com/library"target="_blank" rel="external nofollow noopener noreferrer">Ollama model repository</a>. For example: ton install qwen2:0.5b which is is a new series of large language models from the Alibaba group. Now you will have the option to choose the model from the Open WebUI portal. Moreover, you can also download new models in the settings of the Open WebUI portal.</p>
<h2 id="how-to-start-using-open-webui-later-on" class="heading-element"><span>How to start using Open WebUI later on</span>
  <a href="#how-to-start-using-open-webui-later-on" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><ol>
<li>Start Ollama from the Start menu.</li>
<li>Open Docker Desktop and run the following command in the terminal: <code>docker start open-webui</code></li>
</ol>
<h3 id="troubleshooting" class="heading-element"><span>Troubleshooting</span>
  <a href="#troubleshooting" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>Sometimes, after restarting your PC, you may encounter some port errors with Docker when starting open-webui. In such cases, delete open-webui from Docker and restart your computer. Then run:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker run -d -p 3000:8080 --gpus all --add-host<span class="o">=</span>host.docker.internal:host-gateway -e <span class="nv">OPENAI_API_KEY</span><span class="o">=</span>openai_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda</span></span></code></pre></td></tr></table>
</div>
</div><p>Now, you have a powerful local setup for running a chatbot using large language models. Enjoy!</p>
</div><div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title="Updated on 2024-06-17 00:29:37">Updated on 2024-06-17&nbsp;</span>
      </div><div class="post-info-license">
            <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></span>
          </div></div><div class="post-info-line">
        <div class="post-info-md"></div>
        <div class="post-info-share">
          <span><a href="javascript:void(0);" title="Share on X" data-sharer="twitter" data-url="https://chandrakundu.github.io/posts/how-to-create-ai-chatbot/" data-title="How to Create a Chatbot Like ChatGPT by Running LLM Locally in Windows via Ollama and Open WebUI"><i class="fa-brands fa-x-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://chandrakundu.github.io/posts/how-to-create-ai-chatbot/"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://chandrakundu.github.io/posts/how-to-create-ai-chatbot/"><i class="fa-brands fa-linkedin fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://chandrakundu.github.io/posts/how-to-create-ai-chatbot/" data-title="How to Create a Chatbot Like ChatGPT by Running LLM Locally in Windows via Ollama and Open WebUI" data-web><i class="fa-brands fa-whatsapp fa-fw" aria-hidden="true"></i></a>
  </span>
        </div>
      </div></div>

  <div class="post-info-more">
    <section class="post-tags"></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
    </section>
  </div><div class="post-nav"><a href="/posts/latex-tips-for-effective-typesetting/" class="post-nav-item" rel="prev" title="LaTeX Tips for Effective Typesetting"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>LaTeX Tips for Effective Typesetting</a><a href="/posts/how-to-generate-images-locally-using-open-source-ai-models/" class="post-nav-item" rel="next" title="How to Generate Images Locally Using Open Source AI Models">How to Generate Images Locally Using Open Source AI Models<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="utterances" class="comment"></div><noscript>
        Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/" rel="external nofollow noopener noreferrer">Utterances</a>.
      </noscript></div></article>

  <aside class="toc" id="toc-auto" aria-label="Contents"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.136.3"><img class="hugo-icon" src="/images/hugo.min.svg" alt="Hugo logo" /> Hugo</a> | Theme - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.3.17-30a67c4b"><img class="fixit-icon" src="/images/fixit.min.svg" alt="FixIt logo" /> FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2019 - 2026</span><span class="author" itemprop="copyrightHolder">
              <a href="/"></a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div><div class="fixed-button view-comments d-none" role="button" aria-label="View Comments"><i class="fa-solid fa-comment fa-fw" aria-hidden="true"></i></div></div><div id="mask"></div><div class="reading-progress-bar" style="left: 0;bottom: 0;"></div><noscript>
    <div class="noscript-warning">This website works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/fuse/fuse.min.js" defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":50},"comment":{"enable":true,"expired":false,"utterances":{"darkTheme":"github-dark","issueTerm":"url","label":"","lightTheme":"github-light","repo":"chandrakundu/website-comments"}},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"distance":100,"findAllMatches":false,"highlightTag":"em","ignoreFieldNorm":false,"ignoreLocation":false,"isCaseSensitive":false,"location":0,"maxResultLength":10,"minMatchCharLength":2,"noResultsFound":"No results found","snippetLength":30,"threshold":0.3,"useExtendedSearch":false},"version":"v0.3.17-30a67c4b"};</script><script src="/js/theme.min.js" defer></script><script>
      window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
      gtag('config', 'G-XQ1W5Y3XNQ', { 'anonymize_ip': true });
    </script><script src="https://www.googletagmanager.com/gtag/js?id=G-XQ1W5Y3XNQ" async></script></body>
</html>
